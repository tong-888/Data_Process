# Data_Process 项目 - 数据整理部分代码

本项目主要处理自有的WSJ新闻数据，将不同格式的新闻数据进行读取、去重、合并等操作。其中包含多个 Python 脚本，用于处理不同时间段的新闻数据。

在进行到后续的文本清理和筛选步骤时，我发现在最初就把同一天的所有新闻合并不利于文本分析。因此，我重做了数据整理，没有把同一天的新闻进行合并。

## 日志文件介绍
`processing_log.txt` 记录了每次数据处理任务的关键信息，主要包括： 原始记录总条数、识别并删除的重复条数、处理后剩余记录条数。

## Python 文件介绍

### 1. `1984-2000.py`
- **功能**：读取 `1984-2000.xlsx` 文件，处理日期列，按日期排序，进行去重操作，最后将结果保存为 `1984-2000_combined.csv` 文件。
- **关键步骤**：
  1. 读取 Excel 文件，指定列索引。
  2. 将日期列转换为 `datetime` 类型。
  3. 按日期排序。
  4. 去重（同一日期下的重复）。 
  5. 保存结果为 CSV 文件。

### 2. `2001-2017.py`
- **功能**：读取 `2001-2017.xlsx` 文件，处理日期列，按日期排序，进行去重操作，最后将结果保存为 `2001-2017_combined.csv` 文件。
- **关键步骤**：
  1. 读取 Excel 文件，指定列索引。
  2. 将日期列转换为 `datetime` 类型。
  3. 按日期排序。
  4. 去重（同一日期下的重复）。 
  5. 保存结果为 CSV 文件。

### 3. `2018-2024.6.py`
- **功能**：读取 `2018-2024.6.csv` 文件，处理混合日期格式，按日期排序，进行去重操作，最后将结果保存为 `2018-2024.6_combined.csv` 文件。
- **关键步骤**：
  1. 读取 CSV 文件。
  2. 使用 `parse_mixed_dates` 函数处理混合日期格式。
  3. 按日期排序。
  4. 去重（同一日期下的重复）。 
  5. 保存结果为 CSV 文件。

### 4. `2022.py`
- **功能**：读取 `2018-2024.6.xlsx` 文件，处理日期列（指定日在前的格式），按日期排序，进行去重操作，最后将结果保存为 `2018-2024.6_combined.csv` 文件。
- **关键步骤**：
  1. 读取 Excel 文件。
  2. 将日期列转换为 `datetime` 类型，指定日在前的格式。
  3. 按日期排序。
  4. 去重（同一日期下的重复）。 
  5. 保存结果为 CSV 文件。

### 5. `2024.7-2025.3.py`
- **功能**：读取 `结果2024_7_3to2025_3_15.xlsx` 文件，处理日期列，按日期排序，进行去重操作，最后将结果保存为 `2024.7-2025.3_combined.csv` 文件。
- **关键步骤**：
  1. 读取 Excel 文件。
  2. 将日期列转换为 `datetime` 类型。
  3. 按日期排序。
  4. 去重（同一日期下的重复）。 
  5. 保存结果为 CSV 文件。

### 6. `all_files.py`
- **功能**：将多个 CSV 文件合并为一个大的 CSV 文件 `all_news.csv`，并进行数据清理和按日期排序。
- **关键步骤**：
  1. 配置输入 CSV 文件列表和输出文件名。
  2. 逐个读取 CSV 文件，找到"DATE"和"CONTENT"列。
  3. 合并所有数据。
  4. 清理空行并按日期排序。
  5. 保存最终结果为 CSV 文件。

